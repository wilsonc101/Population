#!/usr/bin/python
import pika
import pymongo
import time
import multiprocessing


import genesis
import unit.create
import unit.update
import unit.destroy
import census.collect

execution_instance = str(int(time.time()))

broker_host = 'localhost'
# broker_port = 5672            # default is assumed by client


mongo_host = 'localhost'
mongo_port = 27017

mongo_db = 'population'
mongo_collection_births = 'births_' + execution_instance
mongo_collection_deaths = 'deaths_' + execution_instance
mongo_collection_matches = 'matches_' + execution_instance
mongo_collection_census = 'census_' + execution_instance


init_pop_count = 1000		# population count to generate in genesis


def _mongo_connect(host, port):
	try:
		mongo_client = pymongo.MongoClient(host, port)
		print("Connected to " + mongo_host + " on port " + str(mongo_port))
		return(mongo_client)

	except:
		mongo_client = 'FALSE'
		raise SystemExit("An error occured connecting to the MongoDB Server")



def _broker_connect(host, port=0):
	try: 
		connection = pika.BlockingConnection(pika.ConnectionParameters(host))
		channel = connection.channel()
		channel.queue_declare(queue='create')
		print("Connected to message broker on " + str(broker_host))
		return(channel)
	except:
		return(None)
	



def _genesis(collection_births, collection_matches, count):
	genesis.StartPopulation(collection_births, collection_matches, count)


def _population(collection_births, collection_deaths, collection_matches, collection_census, broker_connection):

	# Initiate indexes
	collection_births.create_index([("matched", pymongo.DESCENDING),
					("age", pymongo.ASCENDING),
					("gender", pymongo.ASCENDING)])

	collection_matches.create_index([("matched", pymongo.ASCENDING),
					 ("unitA.age", pymongo.ASCENDING),
					 ("unitB.age", pymongo.ASCENDING)])


	iteration = 0
	while 1:

	        iteration += 1
	        # Create Units
		create_worker = multiprocessing.Process(name='create_worker', target=unit.create.Create(collection_births, collection_matches, iteration, broker_connection))
	
	        # Update Units
		update_worker = multiprocessing.Process(name='update_worker', target=unit.update.Update(collection_births, collection_matches, iteration))
	
	        # Destroy Units 
		destroy_worker = multiprocessing.Process(name='destroy_worker', target=unit.destroy.Destroy(collection_births, collection_deaths, iteration))

		create_worker.start()
		update_worker.start()
		destroy_worker.start()

		# Take Census
		census.collect.Collect(collection_census, collection_births, collection_deaths, collection_matches, iteration)

		pop_count = collection_births.count()
		print("the iteration is " + str(iteration) + " , the population count is " + str(pop_count))

		if (pop_count == 0):
			pop_deaths = collection_deaths.count()
			raise SystemExit("Your population is dead, it lasted for " + str(iteration) + " iterations. " + str(pop_deaths) + " units passed through this land." )

		#Rebuild indexes
		collection_births.reindex()
		collection_matches.reindex()

#	        time.sleep(.1)
		



if __name__ == '__main__':
	client = _mongo_connect(mongo_host, mongo_port)

	# Connect to Mongo database and set collection using client connection
	db = client[mongo_db]
	collection_births = db[mongo_collection_births]
	collection_deaths = db[mongo_collection_deaths]
	collection_matches = db[mongo_collection_matches]
	collection_census = db[mongo_collection_census]

	# connect to message broker (rabbitMQ)	
	broker_connection = _broker_connect(broker_host)

	# Run genesis - create population starting point
	_genesis(collection_births, collection_matches, init_pop_count)

	# Run population sim
	_population(collection_births, collection_deaths, collection_matches, collection_census, broker_connection)
	
	





